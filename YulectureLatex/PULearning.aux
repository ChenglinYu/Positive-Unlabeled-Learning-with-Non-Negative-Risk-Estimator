\relax 
\providecommand\hyper@newdestlabel[2]{}
\bbl@cs{beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Background}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}What is PU learning?}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Why PU learning?}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Notation}{2}{subsection.1.3}\protected@file@percent }
\citation{casella2002statistical}
\citation{casella2002statistical}
\citation{casella2002statistical}
\@writefile{toc}{\contentsline {section}{\numberline {2}Preliminaries}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The bias of a point estimator}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}MSE of an estimator}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Consistency of an estimator}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Almost surely}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Estimation error bound of a hypothesis}{4}{subsection.2.5}\protected@file@percent }
\citation{shalev2014understanding}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}The infinity norm of a function}{5}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{"}{5}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Mcdiarmid's inequality}{5}{subsection.2.7}\protected@file@percent }
\citation{ledoux2013probability}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Contraction Lemma}{6}{subsection.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Progress and Motivation}{6}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Earlier}{6}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}unbiased PU learning}{6}{subsection.3.2}\protected@file@percent }
\citation{niu2016theoretical}
\citation{niu2016theoretical}
\@writefile{toc}{\contentsline {section}{\numberline {4}$\setbox \z@ \hbox {\mathsurround \z@ $\textstyle R$}\mathaccent "0365{R}_{\mathrm  {pu}}(g)$ as an estimator}{8}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Bias}{8}{subsection.4.1}\protected@file@percent }
\newlabel{eq:pr-diff-bound}{{4}{10}{Bias}{equation.4.4}{}}
\newlabel{thm:bias-consistency}{{5}{10}{Bias}{equation.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}consistency}{10}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Mean Squared error}{11}{subsection.4.3}\protected@file@percent }
\newlabel{thm:mse}{{4.1}{12}{MSE reduction}{thm.4.1}{}}
\newlabel{eq:mse-cond}{{7}{12}{MSE reduction}{equation.4.7}{}}
\newlabel{eq:cond-sym-loss}{{8}{12}{Mean Squared error}{equation.4.8}{}}
\newlabel{eq:mse-bound}{{9}{13}{Mean Squared error}{equation.4.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}The estimation error bound of $\setbox \z@ \hbox {\mathsurround \z@ $\textstyle g$}\mathaccent "0365{g}_\mathrm  {pu}$}{14}{section.5}\protected@file@percent }
\newlabel{thm:est-err}{{5.1}{14}{Estimation error bound}{thm.5.1}{}}
\newlabel{eq:est-err-bound}{{10}{14}{Estimation error bound}{equation.5.10}{}}
\citation{koltchinskii2001rademacher}
\citation{ledoux2013probability}
\citation{mohri2012foundations}
\citation{shalev2014understanding}
\citation{mohri2012foundations}
\citation{shalev2014understanding}
\citation{ledoux2013probability}
\newlabel{thm:uni-dev}{{5.2}{15}{}{thm.5.2}{}}
\newlabel{eq:uni-dev-bound}{{11}{15}{}{equation.5.11}{}}
\@writefile{toc}{\contentsline {paragraph}{Preliminary}{15}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Proof}{15}{section*.4}\protected@file@percent }
\newlabel{eq:uni-dev-bias}{{13}{15}{Proof}{equation.5.13}{}}
\newlabel{eq:uni-dev-martingale}{{14}{16}{Proof}{equation.5.14}{}}
\newlabel{eq:uni-dev-symmetrization}{{15}{16}{Proof}{equation.5.15}{}}
\citation{niu2016theoretical}
\citation{niu2016theoretical}
\bibdata{yuref.bib}
\bibcite{casella2002statistical}{Casella and Berger, 2002}
\newlabel{eq:uni-dev-rademacher}{{16}{17}{Proof}{equation.5.16}{}}
\newlabel{eq:uni-dev-contraction}{{17}{17}{Proof}{equation.5.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Assumption}{17}{section.6}\protected@file@percent }
\bibcite{koltchinskii2001rademacher}{Koltchinskii, 2001}
\bibcite{ledoux2013probability}{Ledoux and Talagrand, 2013}
\bibcite{mohri2012foundations}{Mohri et~al., 2012}
\bibcite{niu2016theoretical}{Niu et~al., 2016}
\bibcite{shalev2014understanding}{Shalev-Shwartz and Ben-David, 2014}
\bibstyle{apalike}
